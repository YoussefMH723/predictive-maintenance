{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHES = ['data/X_train.csv', 'data/X_test.csv', 'data/y_train.csv', 'data/y_test.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(pathes):\n",
    "    data = []\n",
    "    for path in pathes:\n",
    "        df = pd.read_csv(path)\n",
    "        data.append(df)\n",
    "    return data\n",
    "\n",
    "def train_step(model, data_loader, loss_fn, optimizer):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    for X, y in data_loader:\n",
    "        y_logit = model(X)\n",
    "\n",
    "        loss = loss_fn(y_logit, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted_classes = torch.sigmoid(y_logit).round()\n",
    "        train_acc += (predicted_classes == y).sum().item()/len(predicted_classes)\n",
    "    \n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model, data_loader, loss_fn):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            y_logit = model(X)\n",
    "\n",
    "            test_loss += loss_fn(y_logit, y)\n",
    "\n",
    "            predicted_classes = torch.sigmoid(y_logit).round()\n",
    "            test_acc += (predicted_classes == y).sum().item()/len(predicted_classes)\n",
    "\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        return test_loss, test_acc\n",
    "    \n",
    "def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs):\n",
    "    result = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "    print(\"=================================================\")\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model,\n",
    "                                           train_dataloader,\n",
    "                                           loss_fn,\n",
    "                                           optimizer)\n",
    "        \n",
    "        test_loss, test_acc = test_step(model,\n",
    "                                        test_dataloader,\n",
    "                                        loss_fn)\n",
    "        \n",
    "        result['train_loss'].append(train_loss.item())\n",
    "        result['train_acc'].append(train_acc)\n",
    "        result['test_loss'].append(test_loss.item())\n",
    "        result['test_acc'].append(test_acc)\n",
    "        if epoch%10==1:\n",
    "            print(f\" Epoch: {epoch+1}\")\n",
    "            print(f\"Train Loss = {train_loss:.4f} || Train Accuracy = {train_acc*100:.2f}%\")\n",
    "            print(f\"Test Loss = {test_loss:.4f} || Test Accuracy = {test_acc*100:.2f}%\")\n",
    "            print(\"=================================================\")\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15458, 12)\n",
      "X_test shape: (2000, 12)\n",
      "y_train shape: (15458, 1)\n",
      "y_test shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_data(PATHES)\n",
    "over_sampler = RandomOverSampler()\n",
    "X_train, y_train = over_sampler.fit_resample(X_train, y_train)\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Datasets & Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelV1(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_units, output_shape):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_shape, hidden_units),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden_block = nn.Sequential(\n",
    "            nn.Linear(hidden_units, 4*hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*hidden_units, 2*hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, int(0.5*hidden_units)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(int(0.5*hidden_units), output_shape)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.hidden_block(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating Model, defining loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelV1(\n",
       "  (input_layer): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (hidden_block): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (classifier): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelV1(12, 16, 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Training and Testing loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:02<00:51,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 2\n",
      "Train Loss = 0.3651 || Train Accuracy = 84.40%\n",
      "Test Loss = 0.3192 || Test Accuracy = 85.21%\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:10<00:29,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 12\n",
      "Train Loss = 0.1616 || Train Accuracy = 94.34%\n",
      "Test Loss = 0.2154 || Test Accuracy = 90.62%\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:18<00:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 22\n",
      "Train Loss = 0.1174 || Train Accuracy = 95.89%\n",
      "Test Loss = 0.1582 || Test Accuracy = 93.92%\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:26<00:14,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 32\n",
      "Train Loss = 0.0920 || Train Accuracy = 96.70%\n",
      "Test Loss = 0.1888 || Test Accuracy = 93.47%\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [00:34<00:06,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 42\n",
      "Train Loss = 0.0745 || Train Accuracy = 97.41%\n",
      "Test Loss = 0.1463 || Test Accuracy = 95.54%\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:41<00:00,  1.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.6566299796104431,\n",
       "  0.3651098906993866,\n",
       "  0.2706199884414673,\n",
       "  0.2520017921924591,\n",
       "  0.2307157814502716,\n",
       "  0.21749404072761536,\n",
       "  0.20432783663272858,\n",
       "  0.19326980412006378,\n",
       "  0.18371564149856567,\n",
       "  0.17640969157218933,\n",
       "  0.1711719036102295,\n",
       "  0.1616159826517105,\n",
       "  0.1574690341949463,\n",
       "  0.14979267120361328,\n",
       "  0.14565584063529968,\n",
       "  0.13932619988918304,\n",
       "  0.13743846118450165,\n",
       "  0.13103479146957397,\n",
       "  0.12475506216287613,\n",
       "  0.12295477837324142,\n",
       "  0.1180606558918953,\n",
       "  0.11743919551372528,\n",
       "  0.11098087579011917,\n",
       "  0.11021895706653595,\n",
       "  0.10750296711921692,\n",
       "  0.10732867568731308,\n",
       "  0.10373719036579132,\n",
       "  0.10289754718542099,\n",
       "  0.09804850071668625,\n",
       "  0.09647664427757263,\n",
       "  0.09404963999986649,\n",
       "  0.09202377498149872,\n",
       "  0.08879117667675018,\n",
       "  0.08683337271213531,\n",
       "  0.08354757726192474,\n",
       "  0.08084697276353836,\n",
       "  0.08361440151929855,\n",
       "  0.07916594296693802,\n",
       "  0.08100221306085587,\n",
       "  0.07751110196113586,\n",
       "  0.07381367683410645,\n",
       "  0.07453098893165588,\n",
       "  0.07248295098543167,\n",
       "  0.07048267871141434,\n",
       "  0.07222243398427963,\n",
       "  0.07299601286649704,\n",
       "  0.07280562072992325,\n",
       "  0.06829789280891418,\n",
       "  0.06864289939403534,\n",
       "  0.06459591537714005],\n",
       " 'train_acc': [0.5740885416666667,\n",
       "  0.8440104166666667,\n",
       "  0.8897786458333333,\n",
       "  0.8983072916666667,\n",
       "  0.9095703125,\n",
       "  0.9173177083333334,\n",
       "  0.9240885416666667,\n",
       "  0.9310546875,\n",
       "  0.9360026041666667,\n",
       "  0.9396484375,\n",
       "  0.9396484375,\n",
       "  0.9434244791666667,\n",
       "  0.9447916666666667,\n",
       "  0.9473958333333333,\n",
       "  0.9482421875,\n",
       "  0.9525390625,\n",
       "  0.9526041666666667,\n",
       "  0.95390625,\n",
       "  0.9578776041666667,\n",
       "  0.9579427083333333,\n",
       "  0.9602864583333334,\n",
       "  0.9588541666666667,\n",
       "  0.9625651041666666,\n",
       "  0.9611328125,\n",
       "  0.9628255208333333,\n",
       "  0.9616536458333333,\n",
       "  0.9645182291666666,\n",
       "  0.9638020833333333,\n",
       "  0.9659505208333333,\n",
       "  0.9662109375,\n",
       "  0.965625,\n",
       "  0.9669921875,\n",
       "  0.9680989583333334,\n",
       "  0.9688151041666667,\n",
       "  0.9694661458333333,\n",
       "  0.970703125,\n",
       "  0.9684895833333333,\n",
       "  0.9712890625,\n",
       "  0.9699869791666667,\n",
       "  0.9722005208333333,\n",
       "  0.9731770833333333,\n",
       "  0.9740885416666667,\n",
       "  0.9756510416666667,\n",
       "  0.9751953125,\n",
       "  0.9748697916666667,\n",
       "  0.9760416666666667,\n",
       "  0.9742838541666666,\n",
       "  0.9772135416666666,\n",
       "  0.9764322916666667,\n",
       "  0.9783854166666667],\n",
       " 'test_loss': [0.6709919571876526,\n",
       "  0.31920725107192993,\n",
       "  0.32010218501091003,\n",
       "  0.26459676027297974,\n",
       "  0.2630881667137146,\n",
       "  0.2353614717721939,\n",
       "  0.23981262743473053,\n",
       "  0.1922576129436493,\n",
       "  0.22317573428153992,\n",
       "  0.256434828042984,\n",
       "  0.18597514927387238,\n",
       "  0.21541348099708557,\n",
       "  0.13774563372135162,\n",
       "  0.18505707383155823,\n",
       "  0.22100280225276947,\n",
       "  0.15659460425376892,\n",
       "  0.17991413176059723,\n",
       "  0.16949018836021423,\n",
       "  0.19969990849494934,\n",
       "  0.16021065413951874,\n",
       "  0.1651482731103897,\n",
       "  0.15815047919750214,\n",
       "  0.21215198934078217,\n",
       "  0.1361919343471527,\n",
       "  0.127644345164299,\n",
       "  0.18241648375988007,\n",
       "  0.14095783233642578,\n",
       "  0.1760796159505844,\n",
       "  0.13505755364894867,\n",
       "  0.1301540583372116,\n",
       "  0.15257421135902405,\n",
       "  0.18878023326396942,\n",
       "  0.13834670186042786,\n",
       "  0.15273383259773254,\n",
       "  0.1541285514831543,\n",
       "  0.1331380009651184,\n",
       "  0.15245307981967926,\n",
       "  0.15395058691501617,\n",
       "  0.1291731745004654,\n",
       "  0.14161598682403564,\n",
       "  0.15068747103214264,\n",
       "  0.14629557728767395,\n",
       "  0.1808827966451645,\n",
       "  0.1670515090227127,\n",
       "  0.18818846344947815,\n",
       "  0.1551806479692459,\n",
       "  0.15145516395568848,\n",
       "  0.15473154187202454,\n",
       "  0.1887676864862442,\n",
       "  0.1910480260848999],\n",
       " 'test_acc': [0.6897321428571429,\n",
       "  0.8521205357142857,\n",
       "  0.8537946428571429,\n",
       "  0.8794642857142857,\n",
       "  0.8822544642857143,\n",
       "  0.8950892857142857,\n",
       "  0.8962053571428571,\n",
       "  0.9162946428571429,\n",
       "  0.9012276785714286,\n",
       "  0.890625,\n",
       "  0.9168526785714286,\n",
       "  0.90625,\n",
       "  0.9497767857142857,\n",
       "  0.9280133928571429,\n",
       "  0.9073660714285714,\n",
       "  0.9375,\n",
       "  0.93359375,\n",
       "  0.93359375,\n",
       "  0.92578125,\n",
       "  0.9391741071428571,\n",
       "  0.9380580357142857,\n",
       "  0.9391741071428571,\n",
       "  0.9224330357142857,\n",
       "  0.9497767857142857,\n",
       "  0.9508928571428571,\n",
       "  0.9358258928571429,\n",
       "  0.9475446428571429,\n",
       "  0.9369419642857143,\n",
       "  0.94921875,\n",
       "  0.9536830357142857,\n",
       "  0.9430803571428571,\n",
       "  0.9347098214285714,\n",
       "  0.94921875,\n",
       "  0.9447544642857143,\n",
       "  0.94921875,\n",
       "  0.953125,\n",
       "  0.9458705357142857,\n",
       "  0.9458705357142857,\n",
       "  0.9553571428571429,\n",
       "  0.9508928571428571,\n",
       "  0.9497767857142857,\n",
       "  0.9553571428571429,\n",
       "  0.9430803571428571,\n",
       "  0.9458705357142857,\n",
       "  0.9419642857142857,\n",
       "  0.9520089285714286,\n",
       "  0.9481026785714286,\n",
       "  0.9481026785714286,\n",
       "  0.94140625,\n",
       "  0.9430803571428571]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, train_loader, test_loader, loss_fn, optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "        true_ys = []\n",
    "        pred_ys = []\n",
    "        for X, y in test_loader:\n",
    "            true_ys.append(y)\n",
    "            y_logit = model(X)\n",
    "            predicted_classes = torch.sigmoid(y_logit).round()\n",
    "            pred_ys.append(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.concat(pred_ys).squeeze().numpy()\n",
    "y_true = torch.concat(true_ys).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97      1727\n",
      "         1.0       0.35      0.72      0.47        65\n",
      "\n",
      "    accuracy                           0.94      1792\n",
      "   macro avg       0.67      0.84      0.72      1792\n",
      "weighted avg       0.97      0.94      0.95      1792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
